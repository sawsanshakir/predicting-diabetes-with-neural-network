{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.627   50        1  \n",
      "1                       0.351   31        0  \n",
      "2                       0.672   32        1  \n",
      "3                       0.167   21        0  \n",
      "4                       2.288   33        1  \n",
      "..                        ...  ...      ...  \n",
      "763                     0.171   63        0  \n",
      "764                     0.340   27        0  \n",
      "765                     0.245   30        0  \n",
      "766                     0.349   47        1  \n",
      "767                     0.315   23        0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies:111\n",
      "Glucose:5\n",
      "BloodPressure:35\n",
      "SkinThickness:227\n",
      "Insulin:374\n",
      "BMI:11\n",
      "DiabetesPedigreeFunction:0\n",
      "Age:0\n",
      "Outcome:500\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    missing = df.loc[df[col]==0].shape[0]\n",
    "    print(col+ ':'+ str(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['Glucose']= df['Glucose'].replace(0, np.nan)\n",
    "df['BloodPressure']= df['BloodPressure'].replace(0, np.nan)\n",
    "df['SkinThickness']= df['SkinThickness'].replace(0, np.nan)\n",
    "df['Insulin']= df['Insulin'].replace(0, np.nan)\n",
    "df['BMI']= df['BMI'].replace(0, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "df['Glucose']= df['Glucose'].fillna(df['Glucose'].mean())\n",
    "df['BloodPressure']= df['BloodPressure'].fillna(df['BloodPressure'].mean())\n",
    "df['SkinThickness']= df['SkinThickness'].fillna(df['SkinThickness'].mean())\n",
    "df['Insulin']= df['Insulin'].fillna(df['Insulin'].mean())\n",
    "df['BMI']= df['BMI'].fillna(df['BMI'].mean())\n",
    "\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soona\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "### scale the dataset \n",
    "\n",
    "from sklearn import preprocessing \n",
    "\n",
    "df_scaled = preprocessing.scale(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n",
    "\n",
    "df_scaled['Outcome'] = df['Outcome']\n",
    "df= df_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split the dataset to training and testing datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "features = df.iloc[:,0:8].values\n",
    "labels = df.iloc[:,8].values\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2)\n",
    "\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(train_features, train_labels, test_size = 0.2)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "from keras.layers import Dense\n",
    "model.add(Dense(64, activation='relu', input_dim=8))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "491/491 [==============================] - 0s 789us/step - loss: 0.7135 - accuracy: 0.4664\n",
      "Epoch 2/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.5955 - accuracy: 0.6823\n",
      "Epoch 3/200\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.5315 - accuracy: 0.7332\n",
      "Epoch 4/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.4910 - accuracy: 0.7637\n",
      "Epoch 5/200\n",
      "491/491 [==============================] - 0s 83us/step - loss: 0.4671 - accuracy: 0.7719\n",
      "Epoch 6/200\n",
      "491/491 [==============================] - 0s 76us/step - loss: 0.4521 - accuracy: 0.7719\n",
      "Epoch 7/200\n",
      "491/491 [==============================] - 0s 88us/step - loss: 0.4439 - accuracy: 0.7780\n",
      "Epoch 8/200\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4368 - accuracy: 0.7800\n",
      "Epoch 9/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4310 - accuracy: 0.7943\n",
      "Epoch 10/200\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4262 - accuracy: 0.7902\n",
      "Epoch 11/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4217 - accuracy: 0.7984\n",
      "Epoch 12/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4176 - accuracy: 0.8004\n",
      "Epoch 13/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4141 - accuracy: 0.8045\n",
      "Epoch 14/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4103 - accuracy: 0.8024\n",
      "Epoch 15/200\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.4089 - accuracy: 0.7963\n",
      "Epoch 16/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4029 - accuracy: 0.8065\n",
      "Epoch 17/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4007 - accuracy: 0.8045\n",
      "Epoch 18/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3974 - accuracy: 0.8167\n",
      "Epoch 19/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.3955 - accuracy: 0.8167\n",
      "Epoch 20/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.3915 - accuracy: 0.8208\n",
      "Epoch 21/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3892 - accuracy: 0.8269\n",
      "Epoch 22/200\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.90 - 0s 67us/step - loss: 0.3864 - accuracy: 0.8289\n",
      "Epoch 23/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.3833 - accuracy: 0.8248\n",
      "Epoch 24/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.3812 - accuracy: 0.8269\n",
      "Epoch 25/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.3809 - accuracy: 0.8228\n",
      "Epoch 26/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.3760 - accuracy: 0.8269\n",
      "Epoch 27/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.3725 - accuracy: 0.8289\n",
      "Epoch 28/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.3702 - accuracy: 0.8269\n",
      "Epoch 29/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.3691 - accuracy: 0.8269\n",
      "Epoch 30/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.3666 - accuracy: 0.8310\n",
      "Epoch 31/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.3665 - accuracy: 0.8269\n",
      "Epoch 32/200\n",
      "491/491 [==============================] - 0s 83us/step - loss: 0.3619 - accuracy: 0.8269\n",
      "Epoch 33/200\n",
      "491/491 [==============================] - 0s 77us/step - loss: 0.3598 - accuracy: 0.8289\n",
      "Epoch 34/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3557 - accuracy: 0.8269\n",
      "Epoch 35/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.3543 - accuracy: 0.8289\n",
      "Epoch 36/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.3514 - accuracy: 0.8310\n",
      "Epoch 37/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3484 - accuracy: 0.8330\n",
      "Epoch 38/200\n",
      "491/491 [==============================] - 0s 64us/step - loss: 0.3485 - accuracy: 0.8330\n",
      "Epoch 39/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.3436 - accuracy: 0.8371\n",
      "Epoch 40/200\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.3403 - accuracy: 0.8330\n",
      "Epoch 41/200\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.3398 - accuracy: 0.8391\n",
      "Epoch 42/200\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.3379 - accuracy: 0.8432\n",
      "Epoch 43/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.3340 - accuracy: 0.8411\n",
      "Epoch 44/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.3331 - accuracy: 0.8432\n",
      "Epoch 45/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.3288 - accuracy: 0.8493\n",
      "Epoch 46/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.3304 - accuracy: 0.8493\n",
      "Epoch 47/200\n",
      "491/491 [==============================] - 0s 79us/step - loss: 0.3248 - accuracy: 0.8513\n",
      "Epoch 48/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.3227 - accuracy: 0.8574\n",
      "Epoch 49/200\n",
      "491/491 [==============================] - 0s 76us/step - loss: 0.3188 - accuracy: 0.8595\n",
      "Epoch 50/200\n",
      "491/491 [==============================] - 0s 74us/step - loss: 0.3181 - accuracy: 0.8574\n",
      "Epoch 51/200\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.3142 - accuracy: 0.8635\n",
      "Epoch 52/200\n",
      "491/491 [==============================] - 0s 74us/step - loss: 0.3125 - accuracy: 0.8635\n",
      "Epoch 53/200\n",
      "491/491 [==============================] - 0s 76us/step - loss: 0.3110 - accuracy: 0.8676\n",
      "Epoch 54/200\n",
      "491/491 [==============================] - 0s 94us/step - loss: 0.3080 - accuracy: 0.8676\n",
      "Epoch 55/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3072 - accuracy: 0.8737\n",
      "Epoch 56/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.3044 - accuracy: 0.8737\n",
      "Epoch 57/200\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.3016 - accuracy: 0.8697\n",
      "Epoch 58/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.2995 - accuracy: 0.8717\n",
      "Epoch 59/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.2970 - accuracy: 0.8758\n",
      "Epoch 60/200\n",
      "491/491 [==============================] - 0s 60us/step - loss: 0.2962 - accuracy: 0.8758\n",
      "Epoch 61/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.2933 - accuracy: 0.8778\n",
      "Epoch 62/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.2900 - accuracy: 0.8839\n",
      "Epoch 63/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.2881 - accuracy: 0.8798\n",
      "Epoch 64/200\n",
      "491/491 [==============================] - 0s 104us/step - loss: 0.2872 - accuracy: 0.8798\n",
      "Epoch 65/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.2869 - accuracy: 0.8758\n",
      "Epoch 66/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.2847 - accuracy: 0.8839\n",
      "Epoch 67/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2809 - accuracy: 0.8798\n",
      "Epoch 68/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.2785 - accuracy: 0.8859\n",
      "Epoch 69/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.2770 - accuracy: 0.8880\n",
      "Epoch 70/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.2742 - accuracy: 0.8819\n",
      "Epoch 71/200\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.2718 - accuracy: 0.8859\n",
      "Epoch 72/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.2697 - accuracy: 0.8839\n",
      "Epoch 73/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.2664 - accuracy: 0.8839\n",
      "Epoch 74/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.2672 - accuracy: 0.8839\n",
      "Epoch 75/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2628 - accuracy: 0.8921\n",
      "Epoch 76/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2614 - accuracy: 0.8921\n",
      "Epoch 77/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2578 - accuracy: 0.8900\n",
      "Epoch 78/200\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.2547 - accuracy: 0.8921\n",
      "Epoch 79/200\n",
      "491/491 [==============================] - 0s 74us/step - loss: 0.2547 - accuracy: 0.8941\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 71us/step - loss: 0.2535 - accuracy: 0.8961\n",
      "Epoch 81/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.2478 - accuracy: 0.8961\n",
      "Epoch 82/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2475 - accuracy: 0.8982\n",
      "Epoch 83/200\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.2451 - accuracy: 0.8941\n",
      "Epoch 84/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2432 - accuracy: 0.9022\n",
      "Epoch 85/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.2425 - accuracy: 0.8921\n",
      "Epoch 86/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.2382 - accuracy: 0.8982\n",
      "Epoch 87/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.2367 - accuracy: 0.9002\n",
      "Epoch 88/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.2357 - accuracy: 0.8961\n",
      "Epoch 89/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2347 - accuracy: 0.9002\n",
      "Epoch 90/200\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.2295 - accuracy: 0.9104\n",
      "Epoch 91/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.2286 - accuracy: 0.9022\n",
      "Epoch 92/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.2278 - accuracy: 0.9124\n",
      "Epoch 93/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.2252 - accuracy: 0.9084\n",
      "Epoch 94/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.2276 - accuracy: 0.9084\n",
      "Epoch 95/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.2202 - accuracy: 0.9063\n",
      "Epoch 96/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.2198 - accuracy: 0.9124\n",
      "Epoch 97/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.2177 - accuracy: 0.9206\n",
      "Epoch 98/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.2125 - accuracy: 0.9165\n",
      "Epoch 99/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.2128 - accuracy: 0.9124\n",
      "Epoch 100/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.2118 - accuracy: 0.9124\n",
      "Epoch 101/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.2112 - accuracy: 0.9185\n",
      "Epoch 102/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.2040 - accuracy: 0.9267\n",
      "Epoch 103/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.2053 - accuracy: 0.9246\n",
      "Epoch 104/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.2008 - accuracy: 0.9185\n",
      "Epoch 105/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.2005 - accuracy: 0.9206\n",
      "Epoch 106/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.1965 - accuracy: 0.9267\n",
      "Epoch 107/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.1960 - accuracy: 0.9246\n",
      "Epoch 108/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1937 - accuracy: 0.9267\n",
      "Epoch 109/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1917 - accuracy: 0.9246\n",
      "Epoch 110/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.1884 - accuracy: 0.9308\n",
      "Epoch 111/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1876 - accuracy: 0.9287\n",
      "Epoch 112/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1894 - accuracy: 0.9328\n",
      "Epoch 113/200\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.1835 - accuracy: 0.9328\n",
      "Epoch 114/200\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.1799 - accuracy: 0.9369\n",
      "Epoch 115/200\n",
      "491/491 [==============================] - 0s 78us/step - loss: 0.1804 - accuracy: 0.9369\n",
      "Epoch 116/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.1784 - accuracy: 0.9308\n",
      "Epoch 117/200\n",
      "491/491 [==============================] - 0s 62us/step - loss: 0.1733 - accuracy: 0.9328\n",
      "Epoch 118/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.1788 - accuracy: 0.9287\n",
      "Epoch 119/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1743 - accuracy: 0.9308\n",
      "Epoch 120/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.1696 - accuracy: 0.9389\n",
      "Epoch 121/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.1687 - accuracy: 0.9369\n",
      "Epoch 122/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.1680 - accuracy: 0.9409\n",
      "Epoch 123/200\n",
      "491/491 [==============================] - 0s 82us/step - loss: 0.1718 - accuracy: 0.9389\n",
      "Epoch 124/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.1626 - accuracy: 0.9389\n",
      "Epoch 125/200\n",
      "491/491 [==============================] - 0s 72us/step - loss: 0.1619 - accuracy: 0.9430\n",
      "Epoch 126/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.1599 - accuracy: 0.9430\n",
      "Epoch 127/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.1579 - accuracy: 0.9430\n",
      "Epoch 128/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.1549 - accuracy: 0.9430\n",
      "Epoch 129/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.1555 - accuracy: 0.9430\n",
      "Epoch 130/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.1517 - accuracy: 0.9470\n",
      "Epoch 131/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.1526 - accuracy: 0.9470\n",
      "Epoch 132/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1524 - accuracy: 0.9491\n",
      "Epoch 133/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.1512 - accuracy: 0.9470\n",
      "Epoch 134/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.1478 - accuracy: 0.9532\n",
      "Epoch 135/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1468 - accuracy: 0.9470\n",
      "Epoch 136/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1455 - accuracy: 0.9511\n",
      "Epoch 137/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1413 - accuracy: 0.9532\n",
      "Epoch 138/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.1409 - accuracy: 0.9552\n",
      "Epoch 139/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1397 - accuracy: 0.9470\n",
      "Epoch 140/200\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.1378 - accuracy: 0.9511\n",
      "Epoch 141/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.1361 - accuracy: 0.9552\n",
      "Epoch 142/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.1345 - accuracy: 0.9613\n",
      "Epoch 143/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.1321 - accuracy: 0.9552\n",
      "Epoch 144/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.1340 - accuracy: 0.9613\n",
      "Epoch 145/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1328 - accuracy: 0.9674\n",
      "Epoch 146/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.1284 - accuracy: 0.9613\n",
      "Epoch 147/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1269 - accuracy: 0.9633\n",
      "Epoch 148/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.1242 - accuracy: 0.9613\n",
      "Epoch 149/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.1249 - accuracy: 0.9654\n",
      "Epoch 150/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.1238 - accuracy: 0.9633\n",
      "Epoch 151/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1213 - accuracy: 0.9674\n",
      "Epoch 152/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.1186 - accuracy: 0.9674\n",
      "Epoch 153/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.1194 - accuracy: 0.9715\n",
      "Epoch 154/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1166 - accuracy: 0.9674\n",
      "Epoch 155/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.1157 - accuracy: 0.9674\n",
      "Epoch 156/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.1143 - accuracy: 0.9633\n",
      "Epoch 157/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.1123 - accuracy: 0.9715\n",
      "Epoch 158/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1110 - accuracy: 0.9695\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 67us/step - loss: 0.1106 - accuracy: 0.9695\n",
      "Epoch 160/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.1098 - accuracy: 0.9715\n",
      "Epoch 161/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.1142 - accuracy: 0.9674\n",
      "Epoch 162/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.1063 - accuracy: 0.9817\n",
      "Epoch 163/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1065 - accuracy: 0.9756\n",
      "Epoch 164/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.1040 - accuracy: 0.9715\n",
      "Epoch 165/200\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 1.00 - 0s 62us/step - loss: 0.1002 - accuracy: 0.9796\n",
      "Epoch 166/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.1002 - accuracy: 0.9776\n",
      "Epoch 167/200\n",
      "491/491 [==============================] - 0s 76us/step - loss: 0.1006 - accuracy: 0.9776\n",
      "Epoch 168/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.1006 - accuracy: 0.9735\n",
      "Epoch 169/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.0985 - accuracy: 0.9796\n",
      "Epoch 170/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.0981 - accuracy: 0.9817\n",
      "Epoch 171/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.0981 - accuracy: 0.9796\n",
      "Epoch 172/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.0945 - accuracy: 0.9796\n",
      "Epoch 173/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0956 - accuracy: 0.9756\n",
      "Epoch 174/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0964 - accuracy: 0.9796\n",
      "Epoch 175/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.0917 - accuracy: 0.9817\n",
      "Epoch 176/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0918 - accuracy: 0.9837\n",
      "Epoch 177/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0898 - accuracy: 0.9857\n",
      "Epoch 178/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.0875 - accuracy: 0.9817\n",
      "Epoch 179/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.0847 - accuracy: 0.9837\n",
      "Epoch 180/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0862 - accuracy: 0.9837\n",
      "Epoch 181/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.0836 - accuracy: 0.9878\n",
      "Epoch 182/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0834 - accuracy: 0.9919\n",
      "Epoch 183/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0841 - accuracy: 0.9878\n",
      "Epoch 184/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.0807 - accuracy: 0.9857\n",
      "Epoch 185/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.0791 - accuracy: 0.9898\n",
      "Epoch 186/200\n",
      "491/491 [==============================] - 0s 64us/step - loss: 0.0783 - accuracy: 0.9898\n",
      "Epoch 187/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.0789 - accuracy: 0.9898\n",
      "Epoch 188/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.0789 - accuracy: 0.9898\n",
      "Epoch 189/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.0760 - accuracy: 0.9898\n",
      "Epoch 190/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0753 - accuracy: 0.9898\n",
      "Epoch 191/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0732 - accuracy: 0.9878\n",
      "Epoch 192/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.0710 - accuracy: 0.9898\n",
      "Epoch 193/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0710 - accuracy: 0.9939\n",
      "Epoch 194/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0700 - accuracy: 0.9878\n",
      "Epoch 195/200\n",
      "491/491 [==============================] - 0s 75us/step - loss: 0.0685 - accuracy: 0.9919\n",
      "Epoch 196/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.0690 - accuracy: 0.9878\n",
      "Epoch 197/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.0669 - accuracy: 0.9939\n",
      "Epoch 198/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.0665 - accuracy: 0.9898\n",
      "Epoch 199/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.0666 - accuracy: 0.9919\n",
      "Epoch 200/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.0670 - accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x216dbfad0f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features, train_labels, epochs =200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 220us/step\n",
      "[0.06139539564578451, 0.9959266781806946]\n",
      "154/154 [==============================] - 0s 52us/step\n",
      "[0.894981596764032, 0.7272727489471436]\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(train_features, train_labels)\n",
    "print(train_score)\n",
    "\n",
    "test_score = model.evaluate(test_features, test_labels )\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84 21]\n",
      " [21 28]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "prediction = model.predict_classes(test_features)\n",
    "\n",
    "print(confusion_matrix(test_labels, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
